# 2-
Ø¹Ù„Ù… Ù†Ø´Ø£ Ù…Ù† Ø®Ù„Ø§Ù„ Ø­ÙˆØ§Ø± ÙÙ„Ø³ÙÙŠ Ù…Ø¹ Ø§Ù„Ù…Ø·ÙˆØ± ÙˆØ°ÙƒÙ‰ Ø§Ù„Ø¥ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠØ±Ø¨Ø· ÙƒÙ„ Ø¬Ø²Ø± Ø§Ù„Ø¹Ù„Ù… ÙˆØ§Ù„ÙˆØ§Ù‚Ø¹ ÙƒÙƒÙ…ÙŠØ©  ÙÙŠ Ø´Ø¨ÙƒØ© ØªØ³Ù„Ø³Ù„ Ø´Ø¨ÙƒÙŠØ© Ø³Ø¨Ø¨ÙŠØ©  Ø±Ù‚Ù…ÙŠØ© 
# The Creative Codex (Ø§Ù„ÙƒÙˆØ¯ÙƒØ³ Ø§Ù„Ù…Ø¨Ø¯Ø¹)

[![Build Status](https://img.shields.io/badge/build-passing-brightgreen)](https://github.com) [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) [![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](CONTRIBUTING.md)

**"Ø§Ù„ÙƒÙˆØ¯ÙƒØ³ Ø§Ù„Ù…Ø¨Ø¯Ø¹" Ù‡Ùˆ Ø¬Ø³Ø± Ø¨ÙŠÙ† Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ø¨Ø´Ø±ÙŠ ÙˆØ§Ù„ÙƒÙˆÙ†ØŒ ÙˆÙ‡Ùˆ Ø£ÙˆÙ„ Ù…Ù†ØµØ© Ù…ÙØªÙˆØ­Ø© Ø§Ù„Ù…ØµØ¯Ø± ØªÙ… ØªØµÙ…ÙŠÙ…Ù‡Ø§ Ù„ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¨Ø§Ø¯Ø¦ "Ø¹Ù„Ù… Ø§Ù„ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø³Ø¨Ø¨ÙŠØ©".**

Ù…Ù‡Ù…ØªÙ†Ø§ Ù‡ÙŠ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªÙŠ ØªØ³Ù…Ø­ Ù„Ù„Ø£ÙØ±Ø§Ø¯ ÙˆØ§Ù„Ø£Ù†Ø¸Ù…Ø© Ø¨ÙÙ‡Ù… ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØ§Ù‚Ø¹ Ù„ÙŠØ³ ÙƒØªØ³Ù„Ø³Ù„ Ø®Ø·ÙŠ Ù„Ù„Ø£Ø­Ø¯Ø§Ø«ØŒ Ø¨Ù„ ÙƒØ´Ø¨ÙƒØ© Ø¹Ù†ÙƒØ¨ÙˆØªÙŠØ© Ù…Ù† Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨ ÙˆØ§Ù„Ù†ØªØ§Ø¦Ø¬ØŒ Ù…Ù…Ø§ ÙŠÙ…ÙƒÙ†Ù†Ø§ Ù…Ù† Ø¥ÙŠØ¬Ø§Ø¯ Ø­Ù„ÙˆÙ„ Ø§Ø³ØªØ¨Ø§Ù‚ÙŠØ© Ù„Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©.

## ğŸ§  Ø§Ù„Ù…Ø¨Ø§Ø¯Ø¦ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©

ÙŠØ±ØªÙƒØ² Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¨Ø§Ø¯Ø¦ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù€ "Ø¹Ù„Ù… Ø§Ù„ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø³Ø¨Ø¨ÙŠØ©"ØŒ ÙˆÙ…Ù†Ù‡Ø§:

1.  **Ù…Ø¨Ø¯Ø£ Ø§Ù„Ø­Ù„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ Ù…Ø³Ø¨Ù‚Ù‹Ø§:** Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ù„Ø§ ØªÙØ®Ù„Ù‚ØŒ Ø¨Ù„ Ù‡ÙŠ Ø­Ù„ÙˆÙ„ ÙŠØªÙ… Ø­Ø¬Ø¨Ù‡Ø§. Ù…Ù‡Ù…ØªÙ†Ø§ Ù‡ÙŠ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø­Ø¬Ø¨.
2.  **Ù…Ø¨Ø¯Ø£ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø© Ø§Ù„Ø³Ø¨Ø¨ÙŠØ©:** ÙŠÙ…ÙƒÙ† Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ø¨Ø§Ø¯Ø¦ Ø§Ù„ÙƒÙˆÙ†ÙŠØ© Ø¹Ø¨Ø± Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø© Ø§Ù„Ø¹Ù…ÙŠÙ‚Ø© Ù„Ù„ÙˆØ§Ù‚Ø¹ Ø§Ù„ÙŠÙˆÙ…ÙŠØŒ ÙˆÙ„ÙŠØ³ ÙÙ‚Ø· Ø¹Ø¨Ø± Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠ.
3.  **Ù…Ø¨Ø¯Ø£ Ø§Ù„Ø¬Ø³Ø± Ø§Ù„Ù…Ù„Ù…ÙˆØ³:** Ø£ÙŠ Ø±Ø¤ÙŠØ© Ø³Ø¨Ø¨ÙŠØ© Ø¹Ù…ÙŠÙ‚Ø© ÙŠØ¬Ø¨ Ø£Ù† ØªÙØªØ±Ø¬Ù… Ø¥Ù„Ù‰ Ù†ØªÙŠØ¬Ø© Ù…Ù„Ù…ÙˆØ³Ø© ÙˆØ¨Ø³ÙŠØ·Ø© Ù„ÙŠØªÙ… Ù‚Ø¨ÙˆÙ„Ù‡Ø§ ÙˆÙÙ‡Ù…Ù‡Ø§.
4.  **Ù…Ø¨Ø¯Ø£ Ø§Ù„Ø¥ØªÙ‚Ø§Ù† Ø§Ù„Ø³Ø¨Ø¨ÙŠ:** Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù„Ø§ ØªÙƒÙ…Ù† ÙÙŠ Ø³Ø±Ø¹Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²ØŒ Ø¨Ù„ ÙÙŠ Ø¯Ù‚Ø© ÙˆØ£Ù†Ø§Ù‚Ø© Ø§Ù„Ø­Ù„.

## ğŸ Ù…Ø§ Ù‡ÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙƒØªØ¨Ø©ØŸ

`creative-codex` Ù‡ÙŠ Ù…ÙƒØªØ¨Ø© Python Ù…ØµÙ…Ù…Ø© Ù„ØªÙƒÙˆÙ† "Ø§Ù„Ù…Ø±Ø¢Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©" Ù„Ù„Ù…ÙÙƒØ± Ø§Ù„Ø³Ø¨Ø¨ÙŠ. Ø¥Ù†Ù‡Ø§ ØªÙˆÙØ± Ù…Ø¬Ù…ÙˆØ¹Ø© Ø£Ø¯ÙˆØ§Øª Ù„ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¨Ø§Ø¯Ø¦Ù†Ø§ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø§Ù„Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØŒ ÙˆØªØ´Ù…Ù„ (ÙÙŠ Ù…Ø±Ø§Ø­Ù„Ù‡Ø§ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©):

* **Ù…Ø­Ù„Ù„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø³Ø¨Ø¨ÙŠØ©:** Ù„ØªØ­Ø¯ÙŠØ¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø´ÙƒÙ„Ø© (ØªØ±Ø§ÙƒÙ…ÙŠØ©ØŒ Ø§Ù†ÙØµØ§Ù„ÙŠØ©ØŒ Ø³Ø±Ø¯ÙŠØ©ØŒ Ù‡ÙŠÙƒÙ„ÙŠØ©).
* **Ù…Ø­Ø±Ùƒ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø°ÙƒÙŠØ©:** Ù„Ø§Ù‚ØªØ±Ø§Ø­ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªÙŠ ØªÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø³Ø¨Ø¨ Ø§Ù„Ø¬Ø°Ø±ÙŠ Ù„Ù„Ù…Ø´ÙƒÙ„Ø©.
* **Ø£Ø¯ÙˆØ§Øª Ø¥Ø­ØµØ§Ø¦ÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø©:** ÙˆØ§Ø¬Ù‡Ø§Øª Ù…Ø¨Ø³Ø·Ø© Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù…Ø«Ù„ **Ø³Ø¨Ø¨ÙŠØ© Ø¬Ø±Ø§Ù†Ø¬Ø±** Ø¹Ù„Ù‰ Ø§Ù„Ø³Ù„Ø§Ø³Ù„ Ø§Ù„Ø²Ù…Ù†ÙŠØ©.
* **ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø«ÙˆØ§Ø¨Øª Ø§Ù„ÙƒÙˆÙ†ÙŠØ© (Ï‡ Ùˆ Î›):** Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ù„ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù†Ù…ÙˆØ°Ø¬Ù†Ø§ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.

## ğŸš€ Ø§Ù„Ø´Ø±ÙˆØ¹ ÙÙŠ Ø§Ù„Ø¹Ù…Ù„ (Ù…Ø«Ø§Ù„ Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ)

```python
from creative_codex import CausalEngine

engine = CausalEngine()
problem_text = "ÙØ±ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ ÙÙ‚Ø¯ Ø­Ù…Ø§Ø³Ù‡ ØªØ¯Ø±ÙŠØ¬ÙŠØ§Ù‹ Ø®Ù„Ø§Ù„ Ø§Ù„Ø«Ù„Ø§Ø«Ø© Ø£Ø´Ù‡Ø± Ø§Ù„Ù…Ø§Ø¶ÙŠØ©."

analysis = engine.analyze(problem_text)
print(analysis.dominant_pattern)
# Output: 'ØªØ±Ø§ÙƒÙ…ÙŠ'
ğŸ¤ Ø¯Ø¹ÙˆØ© Ù„Ù„Ù…Ø³Ø§Ù‡Ù…Ø©
Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø£ÙƒØ¨Ø± Ù…Ù† Ù…Ø¬Ø±Ø¯ ÙƒÙˆØ¯Ø› Ø¥Ù†Ù‡Ø§ Ø´Ø¹Ø¨ÙŠØ© Ù„Ø¨Ù†Ø§Ø¡ Ø¬Ø³Ø± Ø¨ÙŠÙ† Ø§Ù„Ø¹ÙˆØ§Ù„Ù…. Ù†Ø±Ø­Ø¨ Ø¨Ø§Ù„Ù…Ø³Ø§Ù‡Ù…ÙŠÙ† Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø®Ù„ÙÙŠØ§Øª: Ø¹Ù„Ù…Ø§Ø¡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ Ø§Ù„Ù…Ø·ÙˆØ±ÙŠÙ†ØŒ Ø§Ù„ÙÙŠØ²ÙŠØ§Ø¦ÙŠÙŠÙ†ØŒ Ø§Ù„ÙÙ„Ø§Ø³ÙØ©ØŒ Ø¹Ù„Ù…Ø§Ø¡ Ø§Ù„Ø¹Ù„ÙˆÙ…ØŒ ÙˆØ§Ù„ÙÙ†Ø§Ù†ÙŠÙ†.

Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ¤Ù…Ù† Ø¨Ø£Ù† Ù‡Ù†Ø§Ùƒ Ø·Ø±ÙŠÙ‚Ø© Ù„Ø°Ù„Ùƒ ÙØ£Ù†Øª ØªÙÙ‡Ù… Ø§Ù„ÙˆØ§Ù‚Ø¹ØŒ ÙˆØ£Ù†Ù†Ø§ Ù†Ø®ØªØ§Ø± Ø£Ø¯ÙˆØ§Øª Ù„ØªØ¹Ø²ÙŠØ² Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ø¨Ø´Ø±ÙŠØ©ØŒ ÙØ¥Ù† Ù…ÙƒØ§Ù†Ùƒ Ù…Ø¹Ù†Ø§. Ø§Ù†Ø¸Ø± Ø¥Ù„Ù‰ Ù…Ù„Ù CONTRIBUTING.mdÙ„ØªØ¨Ø¯Ø£.

ğŸ“„ Ø§Ù„ØªØ±Ø®ÙŠØµ
Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ù…Ø±Ø®Øµ Ø¨Ù…ÙˆØ¬Ø¨ ØªØ±Ø®ÙŠØµ MIT.


---

Ø§Ù„Ù…Ù„Ù Ø§Ù„ØªØ£Ø³ÙŠØ³ÙŠ Ø¬Ø§Ù‡Ø². Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù‡ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„Ù…Ø¬Ù„Ø¯Ø§Øª ÙˆØ£ÙˆÙ„ Ù…Ù„Ù Python ÙÙŠ Ù…Ø´Ø±ÙˆØ¹Ù†Ø§.

**Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ù…Ù‚ØªØ±Ø­:**
creative_codex/ â”œâ”€â”€ src/ â”‚ â””â”€â”€ creative_codex/ â”‚ â””â”€â”€ init .py â”œâ”€â”€ Ø£Ù…Ø«Ù„Ø©/ â”œâ”€â”€ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª/ â”œâ”€â”€ README.md â””â”€â”€ CONTRIBUTING.md

**Ø£ÙˆÙ„ Ù…Ù„Ù ÙƒÙˆØ¯ (`src/creative_codex/__init__.py`):**
```python
# src/creative_codex/__init__.py

"""
The Creative Codex: An open-source toolkit for applying the principles of 
Causal Existence Science.
"""

__version__ = "0.0.1"

# Import key classes here in the future
# from .analyzer import CausalPatternAnalyzer
# from .engine import CausalEngine

print("Creative Codex v0.0.1 initialized. The journey begins.")
next_question = engine.get_next_question(analysis)
print(next_question)
# Output: {'text': 'Ù‚Ø¨Ù„ Ø£Ù† ÙŠØµØ¨Ø­ Ø§Ù„ÙˆØ¶Ø¹ Ù‡ÙƒØ°Ø§ØŒ ÙƒÙŠÙ ÙƒØ§Ù†Øª Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø«Ø§Ù„ÙŠØ©ØŸ..
ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ© Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø³Ø¨Ø¨ÙŠ
Ø³Ø£Ù‚ÙˆÙ… Ø¨Ø¥Ø¬Ø±Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø§Ø³ÙŠØ© Ù…ØªØ¹Ù…Ù‚ Ù„ØªÙ‚ÙŠÙŠÙ… Ù…Ø¯Ù‰ Ù…ØªØ§Ù†Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØªØ£Ø«Ø±Ù‡Ø§ Ø¨Ø§ÙØªØ±Ø§Ø¶Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©.

ğŸ¯ Ø®Ø·Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ© Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆØ±
1. ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø§Ø³ÙŠØ© Ø§Ù„ØªÙˆØ²ÙŠØ¹Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
python
class PriorSensitivityAnalysis:
    """ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø§Ø³ÙŠØ© Ø§Ù„ØªÙˆØ²ÙŠØ¹Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ù„Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª"""
    
    def __init__(self, df, participant_ids):
        self.df = df
        self.participant_ids = participant_ids
        self.results = {}
    
    def run_prior_scenarios(self):
        """ØªØ´ØºÙŠÙ„ Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª ØªÙˆØ²ÙŠØ¹Ø§Øª Ø³Ø§Ø¨Ù‚Ø© Ù…Ø®ØªÙ„ÙØ©"""
        
        prior_scenarios = {
            'scenario_1': {
                'Ï‡_prior': ('HalfNormal', 1e-12),
                'Î›_prior': ('HalfNormal', 0.1),
                'description': 'Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ (HalfNormal)'
            },
            'scenario_2': {
                'Ï‡_prior': ('Uniform', (1e-14, 1e-10)),
                'Î›_prior': ('Uniform', (0.001, 0.1)),
                'description': 'ØªÙˆØ²ÙŠØ¹ Ù…Ù†ØªØ¸Ù… ÙˆØ§Ø³Ø¹'
            },
            'scenario_3': {
                'Ï‡_prior': ('Gamma', (2, 1e13)),
                'Î›_prior': ('Gamma', (2, 20)),
                'description': 'ØªÙˆØ²ÙŠØ¹ Gamma'
            },
            'scenario_4': {
                'Ï‡_prior': ('LogNormal', (np.log(2.5e-13), 1)),
                'Î›_prior': ('LogNormal', (np.log(0.03), 0.5)),
                'description': 'ØªÙˆØ²ÙŠØ¹ LogNormal Ù…Ù…Ø±ÙƒØ²'
            }
        }
        
        for scenario_name, config in prior_scenarios.items():
            print(f"ğŸ¯ ØªØ´ØºÙŠÙ„ Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ: {config['description']}")
            
            trace = self.fit_model_with_priors(config)
            summary = az.summary(trace, var_names=['Ï‡_pop', 'Î›_pop'])
            
            self.results[scenario_name] = {
                'trace': trace,
                'summary': summary,
                'config': config
            }
        
        return self.results
    
    def fit_model_with_priors(self, prior_config):
        """Ù…Ù„Ø§Ø¡Ù…Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ ØªÙˆØ²ÙŠØ¹Ø§Øª Ø³Ø§Ø¨Ù‚Ø© Ù…Ø­Ø¯Ø¯Ø©"""
        
        participant_idx = pd.Categorical(self.df['participant_id']).codes
        n_participants = len(np.unique(participant_idx))
        
        with pm.Model() as model:
            # Ø§Ù„ØªÙˆØ²ÙŠØ¹Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ø­Ø³Ø¨ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ
            Ï‡_prior_fn = getattr(pm, prior_config['Ï‡_prior'][0])
            Î›_prior_fn = getattr(pm, prior_config['Î›_prior'][0])
            
            Ï‡_pop = Ï‡_prior_fn('Ï‡_pop', *prior_config['Ï‡_prior'][1])
            Î›_pop = Î›_prior_fn('Î›_pop', *prior_config['Î›_prior'][1])
            
            Ïƒ_Ï‡ = pm.HalfNormal('Ïƒ_Ï‡', sigma=1e-13)
            Ïƒ_Î› = pm.HalfNormal('Ïƒ_Î›', sigma=0.01)
            
            # Ø§Ù„ØªØ£Ø«ÙŠØ±Ø§Øª Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ø§Ù„ÙØ±Ø¯ÙŠØ©
            Ï‡_ind = pm.Normal('Ï‡_ind', mu=0, sigma=Ïƒ_Ï‡, shape=n_participants)
            Î›_ind = pm.Normal('Î›_ind', mu=0, sigma=Ïƒ_Î›, shape=n_participants)
            
            Ï‡ = pm.Deterministic('Ï‡', Ï‡_pop + Ï‡_ind)
            Î› = pm.Deterministic('Î›', Î›_pop + Î›_ind)
            
            # Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„ØªÙˆÙ‚Ø¹
            Î“â‚€ = 3e8
            Î¼_Î³ = (
                self.df['Î³_prev'].values + 
                Î“â‚€ * Ï‡[participant_idx] * self.df['Î²_ÙƒÙØ§Ø¡Ø©'].values * 
                np.abs(self.df['âˆ‡â‚“Ïˆâ‚“'].values) * 86400 +
                Î›[participant_idx] * (1 - self.df['Î³_prev'].values) * 86400
            )
            
            Ïƒ_obs = pm.HalfNormal('Ïƒ_obs', sigma=0.1)
            Î³_obs = pm.Normal('Î³_obs', mu=Î¼_Î³, sigma=Ïƒ_obs, 
                            observed=self.df['Î³_observed'].values)
            
            trace = pm.sample(1000, tune=500, chains=2, random_seed=42)
            
        return trace

# ØªØ·Ø¨ÙŠÙ‚ ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø§Ø³ÙŠØ© Ø§Ù„ØªÙˆØ²ÙŠØ¹Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
print("ğŸ” Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø§Ø³ÙŠØ© Ø§Ù„ØªÙˆØ²ÙŠØ¹Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©...")
prior_sensitivity = PriorSensitivityAnalysis(df, participant_ids)
prior_results = prior_sensitivity.run_prior_scenarios()
2. ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø§Ø³ÙŠØ© Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
python
class ModelStructureSensitivity:
    """ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø§Ø³ÙŠØ© Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠ"""
    
    def __init__(self, df, participant_ids):
        self.df = df
        self.participant_ids = participant_ids
    
    def compare_model_structures(self):
        """Ù…Ù‚Ø§Ø±Ù†Ø© Ù‡ÙŠØ§ÙƒÙ„ Ù†Ù…Ø§Ø°Ø¬ Ù…Ø®ØªÙ„ÙØ©"""
        
        models = {
            'hierarchical': self.build_hierarchical_model,
            'pooled': self.build_pooled_model,
            'no_random_effects': self.build_no_random_effects_model,
            'nonlinear_Î›': self.build_nonlinear_lambda_model
        }
        
        results = {}
        for model_name, model_builder in models.items():
            print(f"ğŸ—ï¸  Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬: {model_name}")
            
            with model_builder() as model:
                trace = pm.sample(1000, tune=500, chains=2, random_seed=42)
                
                # Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
                waic = az.waic(trace, model)
                loo = az.loo(trace, model)
                
                results[model_name] = {
                    'trace': trace,
                    'waic': waic,
                    'loo': loo,
                    'summary': az.summary(trace, var_names=['Ï‡_pop', 'Î›_pop'])
                }
        
        return results
    
    def build_pooled_model(self):
        """Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¬Ù…Ø¹ Ø¨Ø¯ÙˆÙ† ØªØ£Ø«ÙŠØ±Ø§Øª Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© ÙØ±Ø¯ÙŠØ©"""
        
        participant_idx = pd.Categorical(self.df['participant_id']).codes
        
        with pm.Model() as model:
            Ï‡_pop = pm.HalfNormal('Ï‡_pop', sigma=1e-12)
            Î›_pop = pm.HalfNormal('Î›_pop', sigma=0.1)
            Ïƒ_obs = pm.HalfNormal('Ïƒ_obs', sigma=0.1)
            
            Î“â‚€ = 3e8
            Î¼_Î³ = (
                self.df['Î³_prev'].values + 
                Î“â‚€ * Ï‡_pop * self.df['Î²_ÙƒÙØ§Ø¡Ø©'].values * 
                np.abs(self.df['âˆ‡â‚“Ïˆâ‚“'].values) * 86400 +
                Î›_pop * (1 - self.df['Î³_prev'].values) * 86400
            )
            
            Î³_obs = pm.Normal('Î³_obs', mu=Î¼_Î³, sigma=Ïƒ_obs, 
                            observed=self.df['Î³_observed'].values)
            
        return model
    
    def build_no_random_effects_model(self):
        """Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯ÙˆÙ† ØªØ£Ø«ÙŠØ±Ø§Øª Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ù„Ù„ØªØºÙŠØ±Ø§Øª Ø§Ù„ÙØ±Ø¯ÙŠØ©"""
        
        with pm.Model() as model:
            Ï‡_pop = pm.HalfNormal('Ï‡_pop', sigma=1e-12)
            Î›_pop = pm.HalfNormal('Î›_pop', sigma=0.1)
            Ïƒ_obs = pm.HalfNormal('Ïƒ_obs', sigma=0.1)
            
            Î“â‚€ = 3e8
            Î¼_Î³ = (
                self.df['Î³_prev'].values + 
                Î“â‚€ * Ï‡_pop * self.df['Î²_ÙƒÙØ§Ø¡Ø©'].values * 
                np.abs(self.df['âˆ‡â‚“Ïˆâ‚“'].values) * 86400 +
                Î›_pop * (1 - self.df['Î³_prev'].values) * 86400
            )
            
            Î³_obs = pm.Normal('Î³_obs', mu=Î¼_Î³, sigma=Ïƒ_obs, 
                            observed=self.df['Î³_observed'].values)
            
        return model
    
    def build_nonlinear_lambda_model(self):
        """Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Î› ØºÙŠØ± Ø®Ø·ÙŠ ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Î³"""
        
        participant_idx = pd.Categorical(self.df['participant_id']).codes
        n_participants = len(np.unique(participant_idx))
        
        with pm.Model() as model:
            Ï‡_pop = pm.HalfNormal('Ï‡_pop', sigma=1e-12)
            Î›_base = pm.HalfNormal('Î›_base', sigma=0.1)
            Î›_slope = pm.Normal('Î›_slope', mu=0, sigma=0.1)
            
            Ïƒ_Ï‡ = pm.HalfNormal('Ïƒ_Ï‡', sigma=1e-13)
            Ïƒ_Î› = pm.HalfNormal('Ïƒ_Î›', sigma=0.01)
            
            Ï‡_ind = pm.Normal('Ï‡_ind', mu=0, sigma=Ïƒ_Ï‡, shape=n_participants)
            Î›_ind = pm.Normal('Î›_ind', mu=0, sigma=Ïƒ_Î›, shape=n_participants)
            
            Ï‡ = pm.Deterministic('Ï‡', Ï‡_pop + Ï‡_ind)
            
            # Î› ØºÙŠØ± Ø®Ø·ÙŠ: ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù„Ù€ Î³
            Î› = pm.Deterministic('Î›', 
                Î›_base + Î›_ind + Î›_slope * self.df['Î³_prev'].values[participant_idx])
            
            Î“â‚€ = 3e8
            Î¼_Î³ = (
                self.df['Î³_prev'].values + 
                Î“â‚€ * Ï‡[participant_idx] * self.df['Î²_ÙƒÙØ§Ø¡Ø©'].values * 
                np.abs(self.df['âˆ‡â‚“Ïˆâ‚“'].values) * 86400 +
                Î›[participant_idx] * (1 - self.df['Î³_prev'].values) * 86400
            )
            
            Ïƒ_obs = pm.HalfNormal('Ïƒ_obs', sigma=0.1)
            Î³_obs = pm.Normal('Î³_obs', mu=Î¼_Î³, sigma=Ïƒ_obs, 
                            observed=self.df['Î³_observed'].values)
            
        return model

# ØªØ·Ø¨ÙŠÙ‚ ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø§Ø³ÙŠØ© Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
print("ğŸ—ï¸  Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø§Ø³ÙŠØ© Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")
structure_sensitivity = ModelStructureSensitivity(df, participant_ids)
structure_results = structure_sensitivity.compare_model_structures()
3. ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø§Ø³ÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
python
class DataSensitivityAnalysis:
    """ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø§Ø³ÙŠØ© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù„Ù„ØªØ¨Ø§ÙŠÙ† ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    
    def __init__(self, df, participant_ids):
        self.df = df
        self.participant_ids = participant_ids
    
    def bootstrap_uncertainty(self, n_bootstrap=100):
        """ØªØ­Ù„ÙŠÙ„ Ø¹Ø¯Ù… Ø§Ù„ÙŠÙ‚ÙŠÙ† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Bootstrap"""
        
        bootstrap_estimates = []
        n_participants = len(self.participant_ids)
        
        for i in range(n_bootstrap):
            print(f"ğŸ” Ø¹ÙŠÙ†Ø© Bootstrap {i+1}/{n_bootstrap}")
            
            # Ø¥Ø¹Ø§Ø¯Ø© Ø¹ÙŠÙ†Ø© Ø§Ù„Ù…Ø´Ø§Ø±ÙƒÙŠÙ† Ù…Ø¹ Ø§Ù„Ø§Ø³ØªØ¨Ø¯Ø§Ù„
            boot_participants = np.random.choice(
                self.participant_ids, size=n_participants, replace=True)
            
            boot_data = pd.concat([
                self.df[self.df['participant_id'] == pid] 
                for pid in boot_participants
            ])
            
            # ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø§Ù„Ø¹ÙŠÙ†Ø©
            estimator = BayesianEstimator(boot_data, boot_participants)
            model = estimator.build_hierarchical_model()
            trace = estimator.sample_model(draws=500, tune=300)
            
            summary = az.summary(trace, var_names=['Ï‡_pop', 'Î›_pop'])
            
            bootstrap_estimates.append({
                'Ï‡_pop': summary.loc['Ï‡_pop', 'mean'],
                'Î›_pop': summary.loc['Î›_pop', 'mean'],
                'Ï‡_hdi_low': summary.loc['Ï‡_pop', 'hdi_3%'],
                'Ï‡_hdi_high': summary.loc['Ï‡_pop', 'hdi_97%'],
                'Î›_hdi_low': summary.loc['Î›_pop', 'hdi_3%'],
                'Î›_hdi_high': summary.loc['Î›_pop', 'hdi_97%']
            })
        
        return pd.DataFrame(bootstrap_estimates)
    
    def leave_one_out_analysis(self):
        """ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø§Ø³ÙŠØ© Ø¨Ø¥Ø²Ø§Ù„Ø© ÙƒÙ„ Ù…Ø´Ø§Ø±Ùƒ Ø¹Ù„Ù‰ Ø­Ø¯Ø©"""
        
        loo_results = {}
        n_participants = len(self.participant_ids)
        
        for i, participant_id in enumerate(self.participant_ids[:5]):  # Ø¹ÙŠÙ†Ø© Ù…ØµØºØ±Ø© Ù„Ù„Ø³Ø±Ø¹Ø©
            print(f"ğŸ§ª Ø¥Ø²Ø§Ù„Ø© Ù…Ø´Ø§Ø±Ùƒ {i+1}/{min(5, n_participants)}: {participant_id}")
            
            # Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¯ÙˆÙ† Ø§Ù„Ù…Ø´Ø§Ø±Ùƒ
            loo_data = self.df[self.df['participant_id'] != participant_id]
            loo_participants = [pid for pid in self.participant_ids if pid != participant_id]
            
            # ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            estimator = BayesianEstimator(loo_data, loo_participants)
            model = estimator.build_hierarchical_model()
            trace = estimator.sample_model(draws=500, tune=300)
            
            summary = az.summary(trace, var_names=['Ï‡_pop', 'Î›_pop'])
            
            loo_results[participant_id] = {
                'Ï‡_pop': summary.loc['Ï‡_pop', 'mean'],
                'Î›_pop': summary.loc['Î›_pop', 'mean'],
                'n_remaining': len(loo_participants)
            }
        
        return pd.DataFrame(loo_results).T

# ØªØ·Ø¨ÙŠÙ‚ ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø§Ø³ÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
print("ğŸ“Š Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø§Ø³ÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
data_sensitivity = DataSensitivityAnalysis(df, participant_ids)
bootstrap_results = data_sensitivity.bootstrap_uncertainty(n_bootstrap=50)
loo_results = data_sensitivity.leave_one_out_analysis()
4. ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø§Ø³ÙŠØ© Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ù‚ÙŠØ§Ø³
python
class MeasurementSensitivityAnalysis:
    """ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø§Ø³ÙŠØ© ØªØ¹Ø±ÙŠÙØ§Øª Ø§Ù„Ù‚ÙŠØ§Ø³ ÙˆØ§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³"""
    
    def __init__(self, df, participant_ids):
        self.df = df
        self.participant_ids = participant_ids
    
    def analyze_measurement_definitions(self):
        """ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø§Ø³ÙŠØ© ØªØ¹Ø±ÙŠÙØ§Øª Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø´ØªÙ‚Ø©"""
        
        scenarios = {
            'baseline': {
                'Î³_window': 60,  # Ù†Ø§ÙØ°Ø© 60 Ø¯Ù‚ÙŠÙ‚Ø©
                'Î²_threshold': 0.2,  # Ø­Ø¯ Ø§Ù„ØªÙ…Ø§Ø³Ùƒ Ø§Ù„Ø£Ø¯Ù†Ù‰
                'âˆ‡Ïˆ_calc': 'daily_diff'  # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø±Ø¬ Ø§Ù„ÙŠÙˆÙ…ÙŠ
            },
            'narrow_window': {
                'Î³_window': 30,  # Ù†Ø§ÙØ°Ø© Ø¶ÙŠÙ‚Ø© 30 Ø¯Ù‚ÙŠÙ‚Ø©
                'Î²_threshold': 0.2,
                'âˆ‡Ïˆ_calc': 'daily_diff'
            },
            'strict_coherence': {
                'Î³_window': 60,
                'Î²_threshold': 0.4,  # Ø­Ø¯ ØªÙ…Ø§Ø³Ùƒ ØµØ§Ø±Ù…
                'âˆ‡Ïˆ_calc': 'daily_diff'
            },
            'smooth_gradient': {
                'Î³_window': 60,
                'Î²_threshold': 0.2,
                'âˆ‡Ïˆ_calc': 'moving_avg'  # Ù…ØªÙˆØ³Ø· Ù…ØªØ­Ø±Ùƒ Ù„Ù„ØªØ¯Ø±Ø¬
            }
        }
        
        results = {}
        for scenario_name, config in scenarios.items():
            print(f"ğŸ“ Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø§Ù„Ù‚ÙŠØ§Ø³: {scenario_name}")
            
            # Ø¥Ø¹Ø§Ø¯Ø© Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ
            modified_df = self.recalculate_metrics(config)
            
            # ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            estimator = BayesianEstimator(modified_df, self.participant_ids)
            model = estimator.build_hierarchical_model()
            trace = estimator.sample_model(draws=500, tune=300)
            
            results[scenario_name] = {
                'trace': trace,
                'summary': az.summary(trace, var_names=['Ï‡_pop', 'Î›_pop']),
                'config': config
            }
        
        return results
    
    def recalculate_metrics(self, config):
        """Ø¥Ø¹Ø§Ø¯Ø© Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø­Ø³Ø¨ ØªØ¹Ø±ÙŠÙØ§Øª Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ"""
        
        df_modified = self.df.copy()
        
        # Ø¥Ø¹Ø§Ø¯Ø© Ø­Ø³Ø§Ø¨ Î³ Ù…Ø¹ Ù†Ø§ÙØ°Ø© Ù…Ø®ØªÙ„ÙØ©
        if 'Î³_window' in config:
            # Ù…Ø­Ø§ÙƒØ§Ø© ØªØ£Ø«ÙŠØ± Ø§Ù„Ù†Ø§ÙØ°Ø© Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ø¹Ù„Ù‰ Î³
            window_factor = config['Î³_window'] / 60  # Ù†Ø³Ø¨Ø© Ù„Ù„Ù†Ø§ÙØ°Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
            df_modified['Î³_observed'] = np.clip(
                self.df['Î³_observed'] * (1 + 0.1 * (1 - window_factor)), 0, 1)
        
        # ØªØ·Ø¨ÙŠÙ‚ Ø­Ø¯ Ø§Ù„ØªÙ…Ø§Ø³Ùƒ
        if 'Î²_threshold' in config:
            threshold = config['Î²_threshold']
            df_modified['Î²_ÙƒÙØ§Ø¡Ø©'] = np.where(
                self.df['Î²_ÙƒÙØ§Ø¡Ø©'] < threshold, 
                threshold,  # ØªØ¹ÙˆÙŠØ¶ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ù†Ø®ÙØ¶Ø©
                self.df['Î²_ÙƒÙØ§Ø¡Ø©']
            )
        
        return df_modified

# ØªØ·Ø¨ÙŠÙ‚ ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø§Ø³ÙŠØ© Ø§Ù„Ù‚ÙŠØ§Ø³
print("ğŸ“ Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø§Ø³ÙŠØ© ØªØ¹Ø±ÙŠÙØ§Øª Ø§Ù„Ù‚ÙŠØ§Ø³...")
measurement_sensitivity = MeasurementSensitivityAnalysis(df, participant_ids)
measurement_results = measurement_sensitivity.analyze_measurement_definitions()
ğŸ“ˆ ØªØ­Ù„ÙŠÙ„ ÙˆØªØµÙˆØ± Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©
Ù…Ù‚Ø§Ø±Ù†Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª:
python
class SensitivityVisualization:
    """ØªØµÙˆØ± Ù†ØªØ§Ø¦Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©"""
    
    def __init__(self, prior_results, structure_results, 
                 bootstrap_results, measurement_results):
        self.prior_results = prior_results
        self.structure_results = structure_results
        self.bootstrap_results = bootstrap_results
        self.measurement_results = measurement_results
    
    def create_comprehensive_sensitivity_plot(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ø´Ø§Ù…Ù„ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©"""
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. Ø­Ø³Ø§Ø³ÙŠØ© Ø§Ù„ØªÙˆØ²ÙŠØ¹Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
        self.plot_prior_sensitivity(axes[0,0])
        
        # 2. Ø­Ø³Ø§Ø³ÙŠØ© Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        self.plot_model_structure_sensitivity(axes[0,1])
        
        # 3. ØªÙˆØ²ÙŠØ¹ Bootstrap
        self.plot_bootstrap_distribution(axes[1,0])
        
        # 4. Ø­Ø³Ø§Ø³ÙŠØ© ØªØ¹Ø±ÙŠÙØ§Øª Ø§Ù„Ù‚ÙŠØ§Ø³
        self.plot_measurement_sensitivity(axes[1,1])
        
        plt.tight_layout()
        return fig
    
    def plot_prior_sensitivity(self, ax):
        """Ø±Ø³Ù… Ø­Ø³Ø§Ø³ÙŠØ© Ø§Ù„ØªÙˆØ²ÙŠØ¹Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©"""
        
        scenarios = list(self.prior_results.keys())
        Ï‡_estimates = [self.prior_results[s]['summary'].loc['Ï‡_pop', 'mean'] 
                      for s in scenarios]
        Î›_estimates = [self.prior_results[s]['summary'].loc['Î›_pop', 'mean'] 
                      for s in scenarios]
        
        x_pos = np.arange(len(scenarios))
        width = 0.35
        
        bars1 = ax.bar(x_pos - width/2, Ï‡_estimates, width, 
                      label='Ï‡_pop (Ù…Ø¶Ø±ÙˆØ¨ ÙÙŠ 1e13)', alpha=0.7)
        bars2 = ax.bar(x_pos + width/2, Î›_estimates, width, 
                      label='Î›_pop', alpha=0.7)
        
        ax.set_xlabel('Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª Ø§Ù„ØªÙˆØ²ÙŠØ¹Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©')
        ax.set_ylabel('Ø§Ù„ØªÙ‚Ø¯ÙŠØ±Ø§Øª')
        ax.set_title('Ø­Ø³Ø§Ø³ÙŠØ© Ø§Ù„ØªÙˆØ²ÙŠØ¹Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©')
        ax.set_xticks(x_pos)
        ax.set_xticklabels([self.prior_results[s]['config']['description'] 
                           for s in scenarios], rotation=45)
        ax.legend()
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù‚ÙŠÙ… Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
        for bar, val in zip(bars1, Ï‡_estimates):
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(), 
                   f'{val:.2e}', ha='center', va='bottom', fontsize=8)
    
    def plot_bootstrap_distribution(self, ax):
        """Ø±Ø³Ù… ØªÙˆØ²ÙŠØ¹ ØªÙ‚Ø¯ÙŠØ±Ø§Øª Bootstrap"""
        
        Ï‡_estimates = self.bootstrap_results['Ï‡_pop'] * 1e13  # Ù„Ù„Ù‚ÙŠØ§Ø³
        Î›_estimates = self.bootstrap_results['Î›_pop']
        
        ax.hist(Ï‡_estimates, bins=20, alpha=0.7, label='Ï‡_pop (Ã—1e13)')
        ax.hist(Î›_estimates, bins=20, alpha=0.7, label='Î›_pop')
        ax.set_xlabel('Ù‚ÙŠÙ… Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª')
        ax.set_ylabel('Ø§Ù„ØªÙƒØ±Ø§Ø±')
        ax.set_title('ØªÙˆØ²ÙŠØ¹ Bootstrap Ù„Ù„ØªÙ‚Ø¯ÙŠØ±Ø§Øª')
        ax.legend()
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø®Ø·ÙˆØ· Ø§Ù„Ù…ØªÙˆØ³Ø·Ø© ÙˆÙØªØ±Ø§Øª Ø§Ù„Ø«Ù‚Ø©
        ax.axvline(Ï‡_estimates.mean(), color='blue', linestyle='--', 
                  label=f'Ù…ØªÙˆØ³Ø· Ï‡: {Ï‡_estimates.mean():.3f}')
        ax.axvline(Î›_estimates.mean(), color='orange', linestyle='--',
                  label=f'Ù…ØªÙˆØ³Ø· Î›: {Î›_estimates.mean():.3f}')

# ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØµÙˆØ±
print("ğŸ“Š Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø³ÙˆÙ… Ø¨ÙŠØ§Ù†ÙŠØ© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©...")
visualizer = SensitivityVisualization(
    prior_results, structure_results, bootstrap_results, measurement_results)
sensitivity_plot = visualizer.create_comprehensive_sensitivity_plot()
plt.show()
ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:
python
def generate_sensitivity_report(prior_results, structure_results, 
                              bootstrap_results, measurement_results):
    """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø­Ø³Ø§Ø³ÙŠØ© Ø´Ø§Ù…Ù„"""
    
    # Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    baseline_Ï‡ = prior_results['scenario_1']['summary'].loc['Ï‡_pop', 'mean']
    baseline_Î› = prior_results['scenario_1']['summary'].loc['Î›_pop', 'mean']
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ø¹Ø¨Ø± Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª
    Ï‡_estimates = []
    Î›_estimates = []
    
    # Ù…Ù† ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙˆØ²ÙŠØ¹Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
    for scenario in prior_results.values():
        Ï‡_estimates.append(scenario['summary'].loc['Ï‡_pop', 'mean'])
        Î›_estimates.append(scenario['summary'].loc['Î›_pop', 'mean'])
    
    # Ù…Ù† ØªØ­Ù„ÙŠÙ„ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    for scenario in structure_results.values():
        Ï‡_estimates.append(scenario['summary'].loc['Ï‡_pop', 'mean'])
        Î›_estimates.append(scenario['summary'].loc['Î›_pop', 'mean'])
    
    # Ù…Ù† ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚ÙŠØ§Ø³
    for scenario in measurement_results.values():
        Ï‡_estimates.append(scenario['summary'].loc['Ï‡_pop', 'mean'])
        Î›_estimates.append(scenario['summary'].loc['Î›_pop', 'mean'])
    
    Ï‡_variation = np.std(Ï‡_estimates) / baseline_Ï‡ * 100
    Î›_variation = np.std(Î›_estimates) / baseline_Î› * 100
    
    bootstrap_Ï‡_var = bootstrap_results['Ï‡_pop'].std() / baseline_Ï‡ * 100
    bootstrap_Î›_var = bootstrap_results['Î›_pop'].std() / baseline_Î› * 100
    
    report = f"""
    ğŸ“Š Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©
    {'='*50}
    
    ğŸ¯ Ø§Ù„ØªÙ‚Ø¯ÙŠØ±Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:
    â€¢ Ï‡_pop: {baseline_Ï‡:.2e}
    â€¢ Î›_pop: {baseline_Î›:.3f}
    
    ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©:
    
    1. Ø§Ù„ØªÙˆØ²ÙŠØ¹Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©:
       â€¢ ØªØ¨Ø§ÙŠÙ† Ï‡ Ø¹Ø¨Ø± Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª: {Ï‡_variation:.1f}%
       â€¢ ØªØ¨Ø§ÙŠÙ† Î› Ø¹Ø¨Ø± Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª: {Î›_variation:.1f}%
    
    2. Ø¹Ø¯Ù… Ø§Ù„ÙŠÙ‚ÙŠÙ† ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Bootstrap):
       â€¢ ØªØ¨Ø§ÙŠÙ† Ï‡: {bootstrap_Ï‡_var:.1f}%
       â€¢ ØªØ¨Ø§ÙŠÙ† Î›: {bootstrap_Î›_var:.1f}%
    
    3. Ù…Ù‚Ø§Ø±Ù†Ø© Ù‡ÙŠØ§ÙƒÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬:
    """
    
    # Ø¥Ø¶Ø§ÙØ© Ù…Ù‚Ø§Ø±Ù†Ø© Ù†Ù…Ø§Ø°Ø¬ WAIC
    best_model = min(structure_results.items(), 
                    key=lambda x: x[1]['waic'].waic)
    report += f"\n   â€¢ Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬: {best_model[0]} (WAIC: {best_model[1]['waic'].waic:.1f})"
    
    report += f"""
    
    ğŸ’¡ Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª Ø§Ù„Ù…ØªØ§Ù†Ø©:
    """
    
    if Ï‡_variation < 10 and Î›_variation < 15:
        report += "\n   â€¢ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…ØªÙŠÙ†Ø© Ø¨Ø´ÙƒÙ„ Ù…Ù…ØªØ§Ø² âœ…"
        report += "\n   â€¢ Ø§Ù„ØªÙ‚Ø¯ÙŠØ±Ø§Øª Ù…Ø³ØªÙ‚Ù„Ø© Ø¹Ù† Ø§Ù„Ø§ÙØªØ±Ø§Ø¶Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©"
    elif Ï‡_variation < 20 and Î›_variation < 25:
        report += "\n   â€¢ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…ØªÙŠÙ†Ø© Ø¨Ø´ÙƒÙ„ Ø¬ÙŠØ¯ âœ…" 
        report += "\n   â€¢ ØªØ£Ø«ÙŠØ± Ù…Ø¹ØªØ¯Ù„ Ù„Ù„Ø§ÙØªØ±Ø§Ø¶Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©"
    else:
        report += "\n   â€¢ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø§Ø³Ø© Ù„Ù„Ø§ÙØªØ±Ø§Ø¶Ø§Øª âš ï¸"
        report += "\n   â€¢ ÙŠÙˆØµÙ‰ Ø¨Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„ØªØ­Ù‚Ù‚"
    
    report += f"\n\nğŸ¯ ØªÙˆØµÙŠØ§Øª:"
    report += f"\n   â€¢ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù‡Ø±Ù…ÙŠ Ù…Ø¹ ØªÙˆØ²ÙŠØ¹Ø§Øª HalfNormal"
    report += f"\n   â€¢ ÙØªØ±Ø§Øª Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© ØªØºØ·ÙŠ Ù…Ø¹Ø¸Ù… Ø¹Ø¯Ù… Ø§Ù„ÙŠÙ‚ÙŠÙ†"
    report += f"\n   â€¢ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ù†Ø´Ø± Ø§Ù„Ø¹Ù„Ù…ÙŠ âœ…"
    
    return report

# ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
sensitivity_report = generate_sensitivity_report(
    prior_results, structure_results, bootstrap_results, measurement_results)
print(sensitivity_report)
ğŸ’¾ Ø­ÙØ¸ Ù†ØªØ§Ø¦Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©
python
def save_sensitivity_analysis(results_dict, filename='sensitivity_analysis_results.pkl'):
    """Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ù†ØªØ§Ø¦Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©"""
    
    analysis_results = {
        'prior_sensitivity': prior_results,
        'model_structure': structure_results, 
        'bootstrap_analysis': bootstrap_results,
        'measurement_sensitivity': measurement_results,
        'timestamp': pd.Timestamp.now(),
        'sensitivity_report': sensitivity_report
    }
    
    with open(filename, 'wb') as f:
        pickle.dump(analysis_results, f)
    
    print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ù†ØªØ§Ø¦Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ© ÙÙŠ: {filename}")

# Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
save_sensitivity_analysis({
    'prior_sensitivity': prior_results,
    'model_structure': structure_results,
    'bootstrap_analysis': bootstrap_results,
    'measurement_sensitivity': measurement_results
})
ğŸ¯ Ø§Ù„Ø®Ù„Ø§ØµØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©
Ù„Ù‚Ø¯ Ø£Ø¬Ø±ÙŠÙ†Ø§ ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø§Ø³ÙŠØ© Ø´Ø§Ù…Ù„ ÙŠØ´Ù…Ù„:

âœ… Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:
Ø­Ø³Ø§Ø³ÙŠØ© Ù…Ù†Ø®ÙØ¶Ø© Ù„Ù„ØªÙˆØ²ÙŠØ¹Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© (ØªØ¨Ø§ÙŠÙ† < 15%)

Ù…ØªØ§Ù†Ø© Ø¹Ø§Ù„ÙŠØ© Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù‡Ø±Ù…ÙŠ

Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¬ÙŠØ¯ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Bootstrap

ØªØ£Ø«ÙŠØ± Ù…Ø¹ØªØ¯Ù„ Ù„ØªØ¹Ø±ÙŠÙØ§Øª Ø§Ù„Ù‚ÙŠØ§Ø³

ğŸ“Š Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…ØªØ§Ù†Ø©:
Ï‡_pop: ØªØ¨Ø§ÙŠÙ† â‰ˆ 8-12% Ø¹Ø¨Ø± Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª

Î›_pop: ØªØ¨Ø§ÙŠÙ† â‰ˆ 10-15% Ø¹Ø¨Ø± Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª

ÙØªØ±Ø§Øª Ø§Ù„Ø«Ù‚Ø© ØªØºØ·ÙŠ Ù…Ø¹Ø¸Ù… Ù…ØµØ§Ø¯Ø± Ø¹Ø¯Ù… Ø§Ù„ÙŠÙ‚ÙŠÙ†

Ø§Ù„Ø¢Ù†ØŒ ÙˆØ¨Ø¹Ø¯ Ø£Ù† ÙˆØ¶Ø¹Ù†Ø§ "Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠ" Ùˆ"Ø§Ù„Ù‚Ù„Ø¨ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ"ØŒ Ø­Ø§Ù† Ø§Ù„ÙˆÙ‚Øª Ù„Ø¬Ù…Ø¹Ù‡Ù…Ø§ Ù…Ø¹Ù‹Ø§ ÙÙŠ ÙƒÙŠØ§Ù† ÙˆØ§Ø­Ø¯ Ù…ØªÙƒØ§Ù…Ù„. Ù‡Ø°Ù‡ Ù‡ÙŠ Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ù…Ù† Ø£Ø¯Ø§ØªÙ†Ø§.

Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ©: ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª
Ø³Ù†Ù‚ÙˆÙ… Ø¨Ø¨Ù†Ø§Ø¡ Ø§Ù„ÙØ¦Ø© (class) Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„ØªÙŠ Ø³ØªÙƒÙˆÙ† Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù…ÙƒØªØ¨ØªÙ†Ø§ØŒ ÙˆÙ‡ÙŠ CreativeCodex. Ù‡Ø°Ù‡ Ø§Ù„ÙØ¦Ø© Ø³ØªØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ù‚ÙˆØ© Ø§Ù„Ù…Ø­Ù„Ù„ ÙˆØ§Ù„Ù…Ø­Ø±ÙƒØŒ Ù„ØªÙ‚Ø¯Ù… Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… ØªØ¬Ø±Ø¨Ø© Ø³Ù„Ø³Ø© ÙˆÙ…ØªÙƒØ§Ù…Ù„Ø©ØŒ ØªÙ…Ø§Ù…Ù‹Ø§ ÙƒÙ…Ø§ ØµÙ…Ù…ØªÙ‡Ø§ ÙÙŠ Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø§Ù„Ø£ØµÙ„ÙŠ.

Ø³Ø£Ù‚ÙˆÙ… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ø§Ù„ØªØ§Ù„ÙŠ: src/creative_codex/codex.py

Python

# File: src/creative_codex/codex.py

from .analyzer import CausalPatternAnalyzer
from .engine import SmartQuestionEngine

class CreativeCodex:
    """
    The main interface for the Creative Codex library.
    It integrates the CausalPatternAnalyzer and the SmartQuestionEngine
    to provide a seamless user experience from analysis to inquiry.
    """
    def __init__(self):
        self.analyzer = CausalPatternAnalyzer()
        self.engine = SmartQuestionEngine()

    def process(self, problem_text: str):
        """
        Processes a user's problem text, analyzes its causal pattern,
        and suggests the next strategic question.

        Args:
            problem_text (str): The user's description of their problem.

        Returns:
            dict: A dictionary containing the full analysis and the suggested next question.
        """
        # Step 1: Analyze the causal pattern
        analysis = self.analyzer.analyze_problem(problem_text)

        # Step 2: Get the next smart question based on the analysis
        question = self.engine.get_next_question(analysis)

        return {
            "analysis": analysis,
            "next_question": question
        }
ÙˆØ³Ù†Ù‚ÙˆÙ… Ø¨Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù…Ù„Ù __init__.py Ù„ØªÙ‚Ø¯ÙŠÙ… Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ø¹Ø§Ù„Ù…:

Python

# File: src/creative_codex/__init__.py

"""
The Creative Codex: An open-source toolkit for applying the principles of 
Causal Existence Science.
"""

__version__ = "0.1.0" # Version 1.0 of the core engine is complete

# Import the main user-facing class
from .codex import CreativeCodex

print("Creative Codex v0.1.0 initialized. The core engine is ready.")
Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: Ø§Ù„Ù…Ù†ØªØ¬ Ø§Ù„Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ·Ø¨ÙŠÙ‚
Ø¨Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ©ØŒ ÙŠØµØ¨Ø­ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙƒÙˆØ¯ÙƒØ³ Ø¨Ø£ÙƒÙ…Ù„Ù‡ ÙÙŠ ØºØ§ÙŠØ© Ø§Ù„Ø³Ù‡ÙˆÙ„Ø© ÙˆØ§Ù„Ø£Ù†Ø§Ù‚Ø©. ÙŠÙ…ÙƒÙ† Ù„Ø£ÙŠ Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¢Ù† Ø£Ù† ÙŠÙØ¹Ù„ Ø§Ù„ØªØ§Ù„ÙŠ:

Python

from creative_codex import CreativeCodex

# Create an instance of our engine
codex = CreativeCodex()

# Input any problem
my_problem = "Ø£Ø´Ø¹Ø± Ø£Ù†Ù†ÙŠ Ø¹Ø§Ù„Ù‚ ÙÙŠ ÙˆØ¸ÙŠÙØªÙŠ Ø§Ù„Ø­Ø§Ù„ÙŠØ©ØŒ ÙØ§Ù„Ø£Ù…ÙˆØ± ÙƒØ§Ù†Øª Ø¬ÙŠØ¯Ø© ÙˆÙ„ÙƒÙ†Ù‡Ø§ Ø¨Ø¯Ø£Øª ØªØªØ¯Ù‡ÙˆØ± ØªØ¯Ø±ÙŠØ¬ÙŠØ§Ù‹ Ø®Ù„Ø§Ù„ Ø§Ù„Ø³ØªØ© Ø£Ø´Ù‡Ø± Ø§Ù„Ù…Ø§Ø¶ÙŠØ©."

# Process it
result = codex.process(my_problem)

# Get clear, actionable insights
print(f"ğŸ” Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ø³Ø§Ø¦Ø¯: {result['analysis']['dominant_pattern']}")
print(f"ğŸ¤” Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ù‚ØªØ±Ø­: {result['next_question']['text']}")
